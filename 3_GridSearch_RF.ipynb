{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2b4d0ca-8720-473a-8e33-2551502c7f4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load slicing stage (top-10 features)\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "\n",
    "# Load preprocessed datasets\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready   = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Apply slicer to keep only top-10 features\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk   = slicer_model.transform(val_ready)\n",
    "\n",
    "# Efficient class balancing using sampleBy\n",
    "fractions = {0: 0.6, 1: 1.0}  # 60% of majority, 100% of minority\n",
    "train_sample = train_topk.sampleBy(\"label\", fractions=fractions, seed=42)\n",
    "\n",
    "# Define Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features_topK\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Small param grid (limit depth/trees to avoid long runtimes)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# Evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# TrainValidationSplit (uses entire train_sample for training)\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=1.0,\n",
    "    parallelism=1  # Required for Databricks CE\n",
    ")\n",
    "\n",
    "# Train the model with grid search\n",
    "tvs_model = tvs.fit(train_sample)\n",
    "\n",
    "# Evaluate on external validation set\n",
    "val_preds = tvs_model.transform(val_topk)\n",
    "f1_score = evaluator.evaluate(val_preds)\n",
    "\n",
    "print(f\"Best Random Forest model F1-score on validation set: {f1_score:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "tvs_model.bestModel.write().overwrite().save(\"/FileStore/models/rf_top10_model_grid\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_RF",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}