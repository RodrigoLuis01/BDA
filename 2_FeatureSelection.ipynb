{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78363af7-2fba-434b-bc03-faf0886685ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load preprocessed data\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready   = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "test_ready  = spark.read.format(\"delta\").load(\"/FileStore/data/test_ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b46e2d15-93e4-4ea0-8bd7-0050f4f08664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Train Random Forest on preprocessed training data ----------\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    weightCol=\"weight\",  # Remove if you don't have class weights\n",
    "    numTrees=100,\n",
    "    maxDepth=6,\n",
    "    seed=42\n",
    ")\n",
    "rf_model = rf.fit(train_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3913ce7-f473-4f3e-912b-79948336ac27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 feature indices: [10, 4, 8, 9, 3, 0, 1, 7, 1335, 6]\n"
     ]
    }
   ],
   "source": [
    "# --- Extract top-10 feature indices -----------------------------\n",
    "imp = rf_model.featureImportances.toArray()\n",
    "top_k = 10\n",
    "top_idx = np.argsort(imp)[::-1][:top_k].tolist()\n",
    "print(\"Top-10 feature indices:\", top_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "019ac31c-0047-491d-b64a-d26425f9a608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 10: <hashed_10>\nIndex 4: <hashed_4>\nIndex 8: <hashed_8>\nIndex 9: <hashed_9>\nIndex 3: <hashed_3>\nIndex 0: <hashed_0>\nIndex 1: <hashed_1>\nIndex 7: <hashed_7>\nIndex 1335: <hashed_1335>\nIndex 6: <hashed_6>\n"
     ]
    }
   ],
   "source": [
    "# --- Optional: Map indices to names -----------------------------\n",
    "meta = train_ready.schema[\"features\"].metadata\n",
    "attrs = []\n",
    "\n",
    "for group in [\"numeric\", \"binary\", \"categorical\"]:\n",
    "    if \"ml_attr\" in meta and group in meta[\"ml_attr\"].get(\"attrs\", {}):\n",
    "        attrs += meta[\"ml_attr\"][\"attrs\"][group]\n",
    "\n",
    "name_by_index = [attr[\"name\"] for attr in sorted(attrs, key=lambda x: x[\"idx\"])]\n",
    "for i in top_idx:\n",
    "    name = name_by_index[i] if i < len(name_by_index) else f\"<hashed_{i}>\"\n",
    "    print(f\"Index {i}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d610d7-3872-4a6b-a50e-afbcabbee37d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Create and save VectorSlicer pipeline ----------------------\n",
    "slicer = VectorSlicer(inputCol=\"features\", outputCol=\"features_topK\", indices=top_idx)\n",
    "slicer_pipe = Pipeline(stages=[slicer])\n",
    "slicer_model = slicer_pipe.fit(train_ready)\n",
    "slicer_model.write().overwrite().save(\"/FileStore/models/slicer_top10\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_FeatureSelection_RL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}