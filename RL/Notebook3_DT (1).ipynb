{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d7c9601-c5b1-490f-95b4-59d5b6483b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n✅ Evaluation on validation set:\nF1-score:      0.9463\nPrecision:     0.9344\nRecall:        0.9639\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nConfusion Matrix:\n[[7.13915e+05 6.00000e+00]\n [2.66970e+04 1.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Load slicing stage (top-10 features)\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "\n",
    "# Load datasets\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready   = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Apply slicer to keep only top-10 features\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk   = slicer_model.transform(val_ready)\n",
    "\n",
    "# Step 1: Separate label == 1 (minority) and others\n",
    "minority_df = train_topk.filter(col(\"label\") == 1)\n",
    "majority_df = train_topk.filter(col(\"label\") != 1)\n",
    "\n",
    "# Step 2: Sample 60% of majority class\n",
    "sampled_majority_df = majority_df.sample(withReplacement=False, fraction=0.4, seed=42)\n",
    "\n",
    "# Step 3: Combine all minority with sampled majority\n",
    "train_reduced = sampled_majority_df.union(minority_df)\n",
    "\n",
    "# Define Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features_topK\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Param grid for DT\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(dt.minInstancesPerNode, [1, 5]) \\\n",
    "    .build()\n",
    "\n",
    "# Evaluators\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "\n",
    "# TrainValidationSplit\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=dt,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=f1_evaluator,\n",
    "    trainRatio=0.7,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "tvs_model = tvs.fit(train_reduced)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_preds = tvs_model.transform(val_topk)\n",
    "\n",
    "f1_score = f1_evaluator.evaluate(val_preds)\n",
    "precision = precision_evaluator.evaluate(val_preds)\n",
    "recall = recall_evaluator.evaluate(val_preds)\n",
    "\n",
    "print(\"\\n✅ Evaluation on validation set:\")\n",
    "print(f\"F1-score:      {f1_score:.4f}\")\n",
    "print(f\"Precision:     {precision:.4f}\")\n",
    "print(f\"Recall:        {recall:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "predictionAndLabels = val_preds.select(\"prediction\", \"label\") \\\n",
    "                               .rdd.map(lambda row: (float(row.prediction), float(row.label)))\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "# Save best model\n",
    "tvs_model.bestModel.write().overwrite().save(\"/FileStore/models/dt_top10_model\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_DT",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}