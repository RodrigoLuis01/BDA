{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7df8ae09-6f94-4dd9-ad7b-21d10b51190a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n✅ Evaluation on validation set:\nF1-score:      0.7566\nPrecision:     0.9349\nRecall:        0.6474\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nConfusion Matrix:\n[[468171. 245750.]\n [ 15381.  11317.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# # Load slicing stage (top-10 features)\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "\n",
    "# Load preprocessed datasets (limit for speed)\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready   = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Apply slicer to keep only top-10 features\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk   = slicer_model.transform(val_ready)\n",
    "\n",
    "# # Step 1: Separate label == 1 (minority) and others\n",
    "# minority_df = train_ready.filter(col(\"label\") == 1)\n",
    "# majority_df = train_ready.filter(col(\"label\") != 1)\n",
    "\n",
    "# # Step 2: Sample 60% of majority class\n",
    "# sampled_majority_df = majority_df.sample(withReplacement=False, fraction=0.4, seed=42)\n",
    "\n",
    "# # Step 3: Combine all minority with sampled majority\n",
    "# train_reduced = sampled_majority_df.union(minority_df)\n",
    "\n",
    "# Compute class counts for weights\n",
    "label_counts = train_topk.groupBy(\"label\").count().collect()\n",
    "label_dict = {row[\"label\"]: row[\"count\"] for row in label_counts}\n",
    "total = sum(label_dict.values())\n",
    "\n",
    "# Inverse frequency class weighting\n",
    "class_weights = {label: total / count for label, count in label_dict.items()}\n",
    "\n",
    "# Add class weight column\n",
    "train_weighted = train_topk.withColumn(\n",
    "    \"classWeightCol\",\n",
    "    F.udf(lambda label: float(class_weights[label]), \"double\")(F.col(\"label\"))\n",
    ")\n",
    "\n",
    "# Define Logistic Regression\n",
    "lr = LogisticRegression(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features_topK\",\n",
    "    weightCol=\"classWeightCol\",\n",
    "    maxIter=20\n",
    ")\n",
    "\n",
    "# Grid de parâmetros para LR\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Avaliador primário (F1)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# Avaliadores adicionais\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "\n",
    "# TrainValidationSplit\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=f1_evaluator,\n",
    "    trainRatio=0.7,\n",
    "    parallelism=1\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "tvs_model = tvs.fit(train_weighted)\n",
    "\n",
    "# Avaliação no conjunto de validação externo\n",
    "val_preds = tvs_model.transform(val_topk)\n",
    "\n",
    "f1_score = f1_evaluator.evaluate(val_preds)\n",
    "precision = precision_evaluator.evaluate(val_preds)\n",
    "recall = recall_evaluator.evaluate(val_preds)\n",
    "\n",
    "print(\"\\n✅ Evaluation on validation set:\")\n",
    "print(f\"F1-score:      {f1_score:.4f}\")\n",
    "print(f\"Precision:     {precision:.4f}\")\n",
    "print(f\"Recall:        {recall:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "predictionAndLabels = val_preds.select(\"prediction\", \"label\") \\\n",
    "                               .rdd.map(lambda row: (float(row.prediction), float(row.label)))\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "# Guardar melhor modelo\n",
    "tvs_model.bestModel.write().overwrite().save(\"/FileStore/models/lr_top10_model_weighted\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_LR",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}