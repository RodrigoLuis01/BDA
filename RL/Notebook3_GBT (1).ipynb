{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f7b05ba-a594-4186-a3f0-bb9ac7ab1d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n✅ GBT com Pesos:\nF1-score:  0.3148\nPrecision: 0.9639\nRecall:    0.2217\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nConfusion Matrix:\n[[1.37773e+05 5.76148e+05]\n [2.39000e+02 2.64590e+04]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Carregar modelos e dados\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Aplicar slicer\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk = slicer_model.transform(val_ready)\n",
    "\n",
    "# Balanceamento leve\n",
    "minority_df = train_topk.filter(col(\"label\") == 1)\n",
    "majority_df = train_topk.filter(col(\"label\") != 1)\n",
    "train_balanced = majority_df.sample(False, 0.1, seed=42).union(minority_df)\n",
    "\n",
    "# Calcular pesos por classe (class weights)\n",
    "label_counts = train_balanced.groupBy(\"label\").count().collect()\n",
    "label_dict = {row[\"label\"]: row[\"count\"] for row in label_counts}\n",
    "total = sum(label_dict.values())\n",
    "class_weights = {label: total / count for label, count in label_dict.items()}\n",
    "\n",
    "# Criar UDF para aplicar pesos\n",
    "def get_weight(label):\n",
    "    return float(class_weights[label])\n",
    "\n",
    "weight_udf = F.udf(get_weight, DoubleType())\n",
    "\n",
    "# Adicionar coluna classWeightCol ao DataFrame\n",
    "train_weighted = train_balanced.withColumn(\"classWeightCol\", weight_udf(col(\"label\")))\n",
    "\n",
    "# Definir o classificador GBT com coluna de pesos\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    weightCol=\"classWeightCol\",\n",
    "    maxIter=20,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "model = gbt.fit(train_weighted)\n",
    "\n",
    "# Inferência no conjunto de validação\n",
    "val_preds = model.transform(val_topk)\n",
    "\n",
    "# Avaliação\n",
    "f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\").evaluate(val_preds)\n",
    "precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\").evaluate(val_preds)\n",
    "recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\").evaluate(val_preds)\n",
    "\n",
    "print(f\"\\n✅ GBT com Pesos:\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "preds_rdd = val_preds.select(\"prediction\", \"label\").rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "metrics = MulticlassMetrics(preds_rdd)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "# Guardar modelo\n",
    "model.write().overwrite().save(\"/FileStore/models/gbt_top10_weighted_model\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_GBT",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}