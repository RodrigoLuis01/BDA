{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f7b05ba-a594-4186-a3f0-bb9ac7ab1d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "\n",
    "# Carregar modelos e dados\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Aplicar slicer\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk = slicer_model.transform(val_ready)\n",
    "\n",
    "# Balanceamento leve\n",
    "minority_df = train_topk.filter(col(\"label\") == 1)\n",
    "majority_df = train_topk.filter(col(\"label\") != 1)\n",
    "train_balanced = majority_df.sample(False, 0.01, seed=42).union(minority_df)\n",
    "\n",
    "# Criar coluna de pesos (classe 1 com peso maior)\n",
    "train_balanced = train_balanced.withColumn(\n",
    "    \"classWeightCol\", when(col(\"label\") == 1, 5.0).otherwise(1.0)\n",
    ")\n",
    "\n",
    "# GBT com weightCol\n",
    "gbt = GBTClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features_topK\",\n",
    "    weightCol=\"classWeightCol\",\n",
    "    maxIter=20,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Criar o grid de hiperparâmetros\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxIter, [10, 20, 30])  # Número de árvores\n",
    "             .addGrid(gbt.maxDepth, [3, 5, 7])    # Profundidade máxima\n",
    "             .addGrid(gbt.stepSize, [0.01, 0.1])  # Taxa de aprendizado\n",
    "             .addGrid(gbt.subsamplingRate, [0.8, 1.0])  # Taxa de subamostragem\n",
    "             .build())\n",
    "\n",
    "# Definir o avaliador\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# Configurar validação cruzada\n",
    "crossval = CrossValidator(\n",
    "    estimator=gbt,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,  # Número de dobras para validação cruzada\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "cv_model = crossval.fit(train_balanced)\n",
    "\n",
    "# Obter o melhor modelo\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Exibir os melhores hiperparâmetros\n",
    "print(\"\\n✅ Melhores hiperparâmetros encontrados:\")\n",
    "print(f\"maxIter: {best_model._java_obj.getMaxIter()}\")\n",
    "print(f\"maxDepth: {best_model._java_obj.getMaxDepth()}\")\n",
    "print(f\"stepSize: {best_model._java_obj.getStepSize()}\")\n",
    "print(f\"subsamplingRate: {best_model._java_obj.getSubsamplingRate()}\")\n",
    "\n",
    "# Inferência\n",
    "val_preds = best_model.transform(val_topk)\n",
    "\n",
    "# Avaliação\n",
    "#f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\").evaluate(val_preds)\n",
    "#precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\").evaluate(val_preds)\n",
    "#recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\").evaluate(val_preds)\n",
    "\n",
    "# Avaliação do melhor modelo\n",
    "f1 = evaluator.evaluate(val_preds)\n",
    "precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ").evaluate(val_preds)\n",
    "recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ").evaluate(val_preds)\n",
    "\n",
    "print(f\"\\n✅ GBT com Pesos:\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "\n",
    "# Matriz de confusão\n",
    "preds_rdd = val_preds.select(\"prediction\", \"label\").rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "metrics = MulticlassMetrics(preds_rdd)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "# Guardar modelo\n",
    "best_model.write().overwrite().save(\"/FileStore/models/gbt_top10_weighted_model\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202ad02e-5728-4bbe-ba2e-64b64f1d185a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de classes em train_balanced:\n+-----+------+\n|label| count|\n+-----+------+\n|  0.0|168283|\n|  1.0|501811|\n+-----+------+\n\nDiretório /dbfs/FileStore/tuning_results criado ou já existe.\n\nTreinando modelo 1/1 com parâmetros: {'maxIter': 25, 'maxDepth': 10, 'stepSize': 0.5, 'subsamplingRate': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import col, when\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Inicializar SparkSession para evitar FutureWarning\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Carregar modelos e dados\n",
    "slicer_model = PipelineModel.load(\"/FileStore/models/slicer_top10\")\n",
    "train_ready = spark.read.format(\"delta\").load(\"/FileStore/data/train_ready\")\n",
    "val_ready = spark.read.format(\"delta\").load(\"/FileStore/data/val_ready\")\n",
    "\n",
    "# Aplicar slicer\n",
    "train_topk = slicer_model.transform(train_ready)\n",
    "val_topk = slicer_model.transform(val_ready)\n",
    "\n",
    "# Balanceamento leve\n",
    "minority_df = train_ready.filter(col(\"label\") == 1)\n",
    "majority_df = train_ready.filter(col(\"label\") != 1)\n",
    "train_balanced = majority_df.sample(False, 0.2, seed=42).union(minority_df)\n",
    "\n",
    "# Criar coluna de pesos (aumentar peso da classe minoritária)\n",
    "train_balanced = train_balanced.withColumn(\n",
    "    \"classWeightCol\", when(col(\"label\") == 1, 2.0).otherwise(1.0)\n",
    ")\n",
    "\n",
    "# Cachear dados\n",
    "train_balanced.cache()\n",
    "val_topk.cache()\n",
    "\n",
    "# Depurar: Verificar contagem de classes\n",
    "print(\"Contagem de classes em train_balanced:\")\n",
    "train_balanced.groupBy(\"label\").count().show()\n",
    "\n",
    "# Definir o grid de hiperparâmetros (maior variação)\n",
    "param_grid = {\n",
    "    \"maxIter\": [10],\n",
    "    \"maxDepth\": [10],\n",
    "    \"stepSize\": [0.5],\n",
    "    \"subsamplingRate\": [0.5]\n",
    "}\n",
    "\n",
    "# Criar combinações de hiperparâmetros\n",
    "keys = param_grid.keys()\n",
    "combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "# Lista para armazenar resultados\n",
    "results = []\n",
    "\n",
    "# Avaliador\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "# Verificar e definir caminho de saída\n",
    "output_path = \"/dbfs/FileStore/tuning_results\"\n",
    "try:\n",
    "    dbutils.fs.mkdirs(output_path)\n",
    "    print(f\"Diretório {output_path} criado ou já existe.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar {output_path}: {str(e)}\")\n",
    "    output_path = \"/tmp/tuning_results\"  # Fallback para /tmp\n",
    "    try:\n",
    "        dbutils.fs.mkdirs(output_path)\n",
    "        print(f\"Usando caminho alternativo: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar {output_path}: {str(e)}\")\n",
    "        output_path = \"/dbfs/tmp/tuning_results\"  # Último fallback\n",
    "        dbutils.fs.mkdirs(output_path)\n",
    "        print(f\"Usando caminho final: {output_path}\")\n",
    "\n",
    "# Loop manual sobre combinações de hiperparâmetros\n",
    "for i, combo in enumerate(combinations):\n",
    "    # Extrair hiperparâmetros\n",
    "    params = dict(zip(keys, combo))\n",
    "    max_iter = params[\"maxIter\"]\n",
    "    max_depth = params[\"maxDepth\"]\n",
    "    step_size = params[\"stepSize\"]\n",
    "    subsampling_rate = params[\"subsamplingRate\"]\n",
    "\n",
    "    print(f\"\\nTreinando modelo {i+1}/{len(combinations)} com parâmetros: {params}\")\n",
    "\n",
    "    # Criar e treinar o modelo GBT\n",
    "    gbt = GBTClassifier(\n",
    "        labelCol=\"label\",\n",
    "        featuresCol=\"features_topK\",\n",
    "        weightCol=\"classWeightCol\",\n",
    "        maxIter=max_iter,\n",
    "        maxDepth=max_depth,\n",
    "        stepSize=step_size,\n",
    "        subsamplingRate=subsampling_rate,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo\n",
    "    model = gbt.fit(train_balanced)\n",
    "\n",
    "    # Fazer previsões no conjunto de validação\n",
    "    val_preds = model.transform(val_topk)\n",
    "\n",
    "    # Depurar: Verificar previsões\n",
    "    print(f\"Amostra de previsões para modelo {i+1}:\")\n",
    "    val_preds.select(\"prediction\", \"label\").show(5, truncate=False)\n",
    "\n",
    "    # Avaliar o modelo\n",
    "    f1 = evaluator.evaluate(val_preds)\n",
    "    precision = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"weightedPrecision\"\n",
    "    ).evaluate(val_preds)\n",
    "    recall = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"weightedRecall\"\n",
    "    ).evaluate(val_preds)\n",
    "\n",
    "    # Matriz de confusão\n",
    "    preds_rdd = val_preds.select(\"prediction\", \"label\").rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "    metrics = MulticlassMetrics(preds_rdd)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray().tolist()\n",
    "\n",
    "    # Armazenar resultados\n",
    "    result = {\n",
    "        \"maxIter\": max_iter,\n",
    "        \"maxDepth\": max_depth,\n",
    "        \"stepSize\": step_size,\n",
    "        \"subsamplingRate\": subsampling_rate,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"confusion_matrix\": confusion_matrix\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    print(f\"F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix}\")\n",
    "\n",
    "    # Salvar resultados intermediários no driver node e copiar para DBFS\n",
    "    partial_path_local = f\"/tmp/tuning_results_partial_{i}.csv\"\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(partial_path_local, index=False)\n",
    "    dbutils.fs.cp(f\"file:{partial_path_local}\", f\"{output_path}/tuning_results_partial_{i}.csv\")\n",
    "    print(f\"Resultados parciais salvos em {output_path}/tuning_results_partial_{i}.csv\")\n",
    "\n",
    "# Salvar resultados finais\n",
    "results_df = pd.DataFrame(results)\n",
    "final_path_local = \"/tmp/tuning_results_final.csv\"\n",
    "results_df.to_csv(final_path_local, index=False)\n",
    "dbutils.fs.cp(f\"file:{final_path_local}\", f\"{output_path}/tuning_results_final.csv\")\n",
    "print(f\"\\nResultados finais salvos em {output_path}/tuning_results_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook3_GBT (2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}